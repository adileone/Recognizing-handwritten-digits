{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/media/alessandro/storage/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# imports for array-handling and plotting and time\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# keras imports for the dataset and building neural network\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# sklearn imports for model selection, data preparation and classifiers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "images = np.loadtxt(\"handwritten_digits_images.csv\", delimiter=',')\n",
    "labels = np.loadtxt(\"handwritten_digits_labels.csv\", delimiter=',')\n",
    "\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "images = images.astype('float32')\n",
    "\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "images /= 255\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels,test_size=0.3, random_state=32)\n",
    "\n",
    "#When we are not wrapping our nn into a KerasClassifier we need hot encoded y \n",
    "y_train_enc = np_utils.to_categorical(y_train, 10)\n",
    "y_test_enc = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "images1 = images[1::4]\n",
    "labels1 = labels[1::4]\n",
    "\n",
    "pca = IncrementalPCA(n_components=40, batch_size=100)\n",
    "images_pca = pca.fit_transform(images1)\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(images_pca, labels1,test_size=0.3, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- 1HiddenLayer NN --------------------------------------\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'batch_size': 50, 'nb_epoch': 20}\n",
      "\n",
      "Train on 49000 samples, validate on 21000 samples\n",
      "Epoch 1/15\n",
      " - 5s - loss: 0.2508 - acc: 0.9270 - val_loss: 0.1417 - val_acc: 0.9597\n",
      "Epoch 2/15\n",
      " - 5s - loss: 0.1098 - acc: 0.9669 - val_loss: 0.1038 - val_acc: 0.9683\n",
      "Epoch 3/15\n",
      " - 5s - loss: 0.0766 - acc: 0.9766 - val_loss: 0.0828 - val_acc: 0.9750\n",
      "Epoch 4/15\n",
      " - 5s - loss: 0.0585 - acc: 0.9816 - val_loss: 0.0890 - val_acc: 0.9733\n",
      "Epoch 5/15\n",
      " - 5s - loss: 0.0442 - acc: 0.9860 - val_loss: 0.0756 - val_acc: 0.9778\n",
      "Epoch 6/15\n",
      " - 5s - loss: 0.0360 - acc: 0.9883 - val_loss: 0.0812 - val_acc: 0.9755\n",
      "Epoch 7/15\n",
      " - 5s - loss: 0.0311 - acc: 0.9900 - val_loss: 0.0740 - val_acc: 0.9780\n",
      "Epoch 8/15\n",
      " - 5s - loss: 0.0260 - acc: 0.9918 - val_loss: 0.0722 - val_acc: 0.9789\n",
      "Epoch 9/15\n",
      " - 5s - loss: 0.0252 - acc: 0.9914 - val_loss: 0.0745 - val_acc: 0.9805\n",
      "Epoch 10/15\n",
      " - 5s - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0792 - val_acc: 0.9789\n",
      "Epoch 11/15\n",
      " - 5s - loss: 0.0181 - acc: 0.9939 - val_loss: 0.0734 - val_acc: 0.9817\n",
      "Epoch 12/15\n",
      " - 4s - loss: 0.0162 - acc: 0.9946 - val_loss: 0.0772 - val_acc: 0.9813\n",
      "Epoch 13/15\n",
      " - 5s - loss: 0.0157 - acc: 0.9946 - val_loss: 0.0839 - val_acc: 0.9792\n",
      "Epoch 14/15\n",
      " - 5s - loss: 0.0143 - acc: 0.9950 - val_loss: 0.0900 - val_acc: 0.9786\n",
      "Epoch 15/15\n",
      " - 5s - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0862 - val_acc: 0.9800\n",
      "\n",
      "Test Loss :  0.0861983475477443\n",
      "Test Accuracy :  98.0 %\n",
      "Cross Validation Time :  113.53 sec\n",
      "Training Time :  68.35 sec\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"---------------------- 1HiddenLayer NN --------------------------------------\")\n",
    "print()\n",
    "\n",
    "def make_model1():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))                            \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')    \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def tuning1(X_train,Y_train,X_test,Y_test):\n",
    "\n",
    "    batch_size = [50, 80, 100, 128, 135, 150]\n",
    "    epochs = [15,20,25]\n",
    "    param_grid = dict(batch_size=batch_size, nb_epoch=epochs)\n",
    "\n",
    "    k_model = KerasClassifier(build_fn=make_model1, verbose=0)\n",
    "   \n",
    "    clf = GridSearchCV(estimator=k_model, param_grid=param_grid, \n",
    "                                   cv=3,\n",
    "                                   scoring=\"accuracy\", verbose=0 ,n_jobs=-1)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    model=make_model1()\n",
    "    \n",
    "    return clf,model\n",
    "  \n",
    "tuning1_start = time.time()    \n",
    "clf1 = tuning1(X_train,y_train,X_test,y_test)\n",
    "tuning1_end = time.time()\n",
    "print()\n",
    "model1 = clf1[1]\n",
    "\n",
    "fit1_start=time.time()\n",
    "history1 = model1.fit(X_train,y_train_enc, batch_size=50, epochs=15 ,verbose=2,validation_data=(X_test, y_test_enc))\n",
    "fit1_end=time.time()\n",
    "\n",
    "#Evaluating the model\n",
    "loss1, accuracy1 = model1.evaluate(X_test, y_test_enc, verbose=2)\n",
    "\n",
    "print()\n",
    "print(\"Test Loss : \", loss1)\n",
    "print(\"Test Accuracy : \", round(accuracy1*100, 2), \"%\")\n",
    "print(\"Cross Validation Time : \", round(tuning1_end-tuning1_start, 2), \"sec\" )\n",
    "print(\"Training Time : \",  round(fit1_end-fit1_start, 2), \"sec\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Convolutional NN --------------------------------------\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'nb_epoch': 1}\n",
      "\n",
      "Train on 49000 samples, validate on 21000 samples\n",
      "Epoch 1/3\n",
      "49000/49000 [==============================] - 15s 312us/step - loss: 0.2947 - acc: 0.9064 - val_loss: 0.0959 - val_acc: 0.9719\n",
      "Epoch 2/3\n",
      "49000/49000 [==============================] - 15s 311us/step - loss: 0.1035 - acc: 0.9691 - val_loss: 0.0683 - val_acc: 0.9781\n",
      "Epoch 3/3\n",
      "49000/49000 [==============================] - 15s 312us/step - loss: 0.0777 - acc: 0.9755 - val_loss: 0.0552 - val_acc: 0.9837\n",
      "\n",
      "Test Loss :  0.055206523373013454\n",
      "Test Accuracy :  98.37 %\n",
      "Cross Validation Time :  224.88 sec\n",
      "Training Time :  46.01 sec\n",
      "\n",
      "20657  classified correctly\n",
      "343  classified incorrectly\n",
      "\n",
      "Error rate :  1.63 %\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"---------------------- Convolutional NN --------------------------------------\")\n",
    "print()\n",
    "\n",
    "#reshape data to fit model\n",
    "X_train_conv = X_train.reshape(49000,28,28,1)\n",
    "X_test_conv = X_test.reshape(21000,28,28,1)\n",
    "\n",
    "def make_model2():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(10,kernel_size=5, activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(20, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])   \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def tuning2(X_train,Y_train,X_test,Y_test):\n",
    "\n",
    "    \n",
    "    epochs = list(range(1,5))\n",
    "    param_grid = dict(nb_epoch=epochs)\n",
    "\n",
    "    k_model = KerasClassifier(build_fn=make_model2, verbose=0)\n",
    "   \n",
    "    clf = GridSearchCV(estimator=k_model, param_grid=param_grid, \n",
    "                                   cv=5,\n",
    "                                   scoring=\"accuracy\", verbose=0 ,n_jobs=-1)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    model=make_model2()\n",
    "    \n",
    "    return clf,model\n",
    "    \n",
    "tuning2_start = time.time()    \n",
    "clf2 = tuning2(X_train_conv,y_train,X_test_conv,y_test)\n",
    "tuning2_end = time.time()\n",
    "print()\n",
    "model2 = clf2[1]\n",
    "\n",
    "fit2_start=time.time()\n",
    "history2 = model2.fit(X_train_conv, y_train_enc, validation_data=(X_test_conv, y_test_enc), epochs=3)\n",
    "fit2_end=time.time()\n",
    "\n",
    "#Evaluating the model\n",
    "loss2, accuracy2 = model2.evaluate(X_test_conv, y_test_enc, verbose=2)\n",
    "\n",
    "print()\n",
    "print(\"Test Loss : \", loss2)\n",
    "print(\"Test Accuracy : \", round(accuracy2*100, 2), \"%\")\n",
    "print(\"Cross Validation Time : \", round(tuning2_end-tuning2_start, 2), \"sec\" )\n",
    "print(\"Training Time : \",  round(fit2_end-fit2_start, 2), \"sec\"  )\n",
    "\n",
    "predicted_classes = model2.predict_classes(X_test_conv)\n",
    "\n",
    "# see which we predicted correctly and which not ----- Indices of elements that are non-zero.\n",
    "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "\n",
    "print()\n",
    "print(len(correct_indices),\" classified correctly\")\n",
    "print(len(incorrect_indices),\" classified incorrectly\")\n",
    "\n",
    "error_rate = len(incorrect_indices)/(len(correct_indices)+len(incorrect_indices))\n",
    "\n",
    "print()\n",
    "print(\"Error rate : \", round(error_rate*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- K-NN Classifier --------------------------------------\n",
      "\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 3}\n",
      "\n",
      "Test Accuracy :  96.34 %\n",
      "Cross Validation Time :  0.0 sec\n",
      "Training Time :  42.37 sec\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"---------------------- K-NN Classifier --------------------------------------\")\n",
    "print()\n",
    "\n",
    "KnnClassifier=KNeighborsClassifier()\n",
    "\n",
    "grid_params = {\"n_neighbors\": range(1, 10)}\n",
    "\n",
    "tuning3_start = time.time()    \n",
    "grid_search = GridSearchCV(KnnClassifier, grid_params, verbose=0, n_jobs=-1)\n",
    "tuning3_end = time.time()\n",
    "\n",
    "fit3_start=time.time()\n",
    "grid_search.fit(X_train3, y_train3)\n",
    "fit3_end=time.time()\n",
    "\n",
    "predicted = grid_search.predict(X_test3)\n",
    "acc = accuracy_score(y_test3, predicted)\n",
    "\n",
    "print()\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print()\n",
    "print(\"Test Accuracy : \", round(acc*100, 2), \"%\")\n",
    "print(\"Cross Validation Time : \", round(tuning3_end-tuning3_start, 2), \"sec\" )\n",
    "print(\"Training Time : \",  round(fit3_end-fit3_start, 2), \"sec\"  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- RandomForest Classifier --------------------------------------\n",
      "\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 19}\n",
      "\n",
      "Test Accuracy :  95.57 %\n",
      "Cross Validation Time :  0.0 sec\n",
      "Training Time :  32.08 sec\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"---------------------- RandomForest Classifier --------------------------------------\")\n",
    "print()\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "grid_params1 = {\"n_estimators\": range(1, 20)}\n",
    "\n",
    "tuning4_start = time.time()    \n",
    "grid_search1 = GridSearchCV(rfc, grid_params1, verbose=0, n_jobs=-1)\n",
    "tuning4_end = time.time()\n",
    "\n",
    "fit4_start=time.time()\n",
    "grid_search1.fit(X_train, y_train)\n",
    "fit4_end=time.time()\n",
    "\n",
    "predicted1 = grid_search1.predict(X_test)\n",
    "acc1 = accuracy_score(y_test, predicted1)\n",
    "\n",
    "print()\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_search1.best_params_)\n",
    "\n",
    "print()\n",
    "print(\"Test Accuracy : \", round(acc1*100, 2), \"%\")\n",
    "print(\"Cross Validation Time : \", round(tuning4_end-tuning4_start, 2), \"sec\" )\n",
    "print(\"Training Time : \",  round(fit4_end-fit4_start, 2), \"sec\"  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
